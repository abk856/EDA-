{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30e54b32",
   "metadata": {},
   "source": [
    "# EDA\n",
    "\n",
    "Contents of the Notebook:\n",
    "\n",
    "Exploratory Data Analysis(EDA):\n",
    "\n",
    "1. Analysis of the features.\n",
    "2. Finding any relation or treds considering multiple features.\n",
    "3. Filling Null Values.\n",
    "4. Transforming Variable for Model consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c3fbe",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis(EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331333c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3c64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(x):\n",
    "    return x.quantile(q=0.75) - x.quantile(q=0.25)\n",
    "\n",
    "## Outliers > 75th , tile + 1.5IQR & < 25th tile - 1.5IQR\n",
    "\n",
    "def outlier_count(x):\n",
    "    upper_out = x.quantile(q=0.75) + 1.5 * iqr(x)\n",
    "    lower_out = x.quantile(q=0.25) - 1.5 * iqr(x)\n",
    "    \n",
    "    return len(x[x > upper_out]) + len(x[x < lower_out])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c70c04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'D:\\EDA\\titanic\\train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4bc5a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>...</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>WikiId</th>\n",
       "      <th>Name_wiki</th>\n",
       "      <th>Age_wiki</th>\n",
       "      <th>Hometown</th>\n",
       "      <th>Boarded</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Lifeboat</th>\n",
       "      <th>Body</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>691.0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Bridgerule, Devon, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Qu'Appelle Valley, Saskatchewan, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>...</td>\n",
       "      <td>C</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Cumings, Mrs. Florence Briggs (née Thayer)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>New York, New York, US</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>865.0</td>\n",
       "      <td>Heikkinen, Miss Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Jyväskylä, Finland</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>14?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>127.0</td>\n",
       "      <td>Futrelle, Mrs. Lily May (née Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Scituate, Massachusetts, US</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>...</td>\n",
       "      <td>S</td>\n",
       "      <td>627.0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Birmingham, West Midlands, England</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>New York City</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare  ... Embarked WikiId  \\\n",
       "0      0         A/5 21171   7.2500  ...        S  691.0   \n",
       "1      0          PC 17599  71.2833  ...        C   90.0   \n",
       "2      0  STON/O2. 3101282   7.9250  ...        S  865.0   \n",
       "3      0            113803  53.1000  ...        S  127.0   \n",
       "4      0            373450   8.0500  ...        S  627.0   \n",
       "\n",
       "                                    Name_wiki Age_wiki  \\\n",
       "0                     Braund, Mr. Owen Harris     22.0   \n",
       "1  Cumings, Mrs. Florence Briggs (née Thayer)     35.0   \n",
       "2                       Heikkinen, Miss Laina     26.0   \n",
       "3          Futrelle, Mrs. Lily May (née Peel)     35.0   \n",
       "4                    Allen, Mr. William Henry     35.0   \n",
       "\n",
       "                             Hometown      Boarded  \\\n",
       "0          Bridgerule, Devon, England  Southampton   \n",
       "1              New York, New York, US    Cherbourg   \n",
       "2                  Jyväskylä, Finland  Southampton   \n",
       "3         Scituate, Massachusetts, US  Southampton   \n",
       "4  Birmingham, West Midlands, England  Southampton   \n",
       "\n",
       "                               Destination Lifeboat Body Class  \n",
       "0  Qu'Appelle Valley, Saskatchewan, Canada      NaN  NaN   3.0  \n",
       "1                   New York, New York, US        4  NaN   1.0  \n",
       "2                            New York City      14?  NaN   3.0  \n",
       "3              Scituate, Massachusetts, US        D  NaN   1.0  \n",
       "4                            New York City      NaN  NaN   3.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70677db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 21 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    float64\n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      " 12  WikiId       889 non-null    float64\n",
      " 13  Name_wiki    889 non-null    object \n",
      " 14  Age_wiki     887 non-null    float64\n",
      " 15  Hometown     889 non-null    object \n",
      " 16  Boarded      889 non-null    object \n",
      " 17  Destination  889 non-null    object \n",
      " 18  Lifeboat     345 non-null    object \n",
      " 19  Body         87 non-null     object \n",
      " 20  Class        889 non-null    float64\n",
      "dtypes: float64(6), int64(4), object(11)\n",
      "memory usage: 146.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6034ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-d78ada7b36c4>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-d78ada7b36c4>\"\u001b[1;36m, line \u001b[1;32m36\u001b[0m\n\u001b[1;33m    data_info.loc[0, '% of Variables having complete cases'] = null_per[null_per]=[ 0 ]hape[0]*100\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def data_information(df, id_cols):\n",
    "    \n",
    "    ## Removing ID columns\n",
    "    df = df.drop(columns = id_cols)\n",
    "    \n",
    "    ## Creating Empty Data Frame\n",
    "    data_info = pd.DataFrame(np.random.randn(0, 12) * 0 , \n",
    "                             columns = ['No. of Observations (Nrow)',\n",
    "                                        'No. of Numeric Variable',\n",
    "                                        'No of Factor Variables',\n",
    "                                        'No. of Categorical Variables',\n",
    "                                        'No. of Logical Variable',\n",
    "                                        'No. of Date Variable',\n",
    "                                        'No of Zero variance Variables (Uniform)',\n",
    "                                        '% of Variables having complete cases', \n",
    "                                        '% of Variables having <= 50% missing cases',\n",
    "                                        '% of Variables having >50% missing cases',\n",
    "                                        '% of Variables having >90% missing cases'])\n",
    "    \n",
    "    \n",
    "    ## Data Information\n",
    "    \n",
    "    data_info.loc[0, 'No. of Observations (Nrow)'] = df.shape[0]\n",
    "    data_info.loc[0, 'No. of Variables (Ncol)'] = df.shape[1]\n",
    "    data_info.loc[0, 'No. of Numerical Variable'] = df._get_numeric_data().shape[1]\n",
    "    data_info.loc[0, 'No. of Factor Variables'] = df.select_dtypes(include = 'category').shape[1]\n",
    "    data_info.loc[0, 'No. of Logical Variables'] = df.select_dtypes(include = 'bool').shape[1]\n",
    "    data_info.loc[0, 'No. of Categorical Variables'] = df.select_dtypes(include = 'object').shape[1]\n",
    "    data_info.loc[0, 'No. of Date Variable'] = df.select_dtypes(include = 'datetime64').shape[1]\n",
    "    data_info.loc[0, 'No. of Zero Variance Variables (Uniform)' ] = df.loc[:, df.apply(pd.Series.numique)== 1 ].shape[1]\n",
    "                                                                                       \n",
    "    null_per = pd.DataFrame(df.isnull().sum() / df.shape[0])\n",
    "    null_per.columns = ['null_per'\n",
    "    \n",
    "                        \n",
    "    data_info.loc[0, '% of Variables having complete cases'] = null_per[null_per]=[ 0 ]hape[0]*100\n",
    "    data_info.loc[0, '% of Variables having <=50% missing cases'] = null_per[null_per.null_per<= 0.50].shape[0]*100\n",
    "    data_info.loc[0, '% of Variables having >50% missing cases'] = null_per[null.per.null_per > 0.5].shape[0]*100\n",
    "    data_info.loc[0, '% of Variables having >90% missing cases ] = null_per[null_per.null_per > 0.9].shape[0]*100\n",
    "                  \n",
    "                  \n",
    "     ## Transposing Data to get in consumable format\n",
    "                  \n",
    "     data_info = data_info.transpose()\n",
    "     data_info.columns = ['Value']\n",
    "     data['Value'] = data_info['Value'].astype(int)\n",
    "     \n",
    "    \n",
    "     return data_info-input-26-154714532f69>\", line 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3400073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
